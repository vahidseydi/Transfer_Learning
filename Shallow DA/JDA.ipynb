{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Distribution Adaptation (JDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JDA jointly aligns both marginal and conditional distributions of source and target domains in a less dimensional subspace.\n",
    "\n",
    "For this purpose, the maximum mean difference (MMD) is used to measure the difference of both marginal distributions and conditional distributions between source and target domains. The PCA method is also used to construct feature representations into the lower-dimensional subspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "Long M, Wang J, Ding G, et al. Transfer feature learning with joint distribution adaptation. Proceedings of the IEEE international conference on computer vision. 2013: 2200-2207."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.linalg\n",
    "import sklearn.metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(ker, X1, X2, gamma):\n",
    "    K = None\n",
    "    if not ker or ker == 'primal':\n",
    "        K = X1\n",
    "    elif ker == 'linear':\n",
    "        if X2:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1).T, np.asarray(X2).T)\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1).T)\n",
    "    elif ker == 'rbf':\n",
    "        if X2:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1).T, np.asarray(X2).T, gamma)\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1).T, None, gamma)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data in the target domain is unlabeled, the conditional probability in the target domain cannot be directly modeled. So here, a pseudo labels finder for the target domain is proposed which can be applied to the target domain by utilizing the source trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JDA:\n",
    "    def __init__(self, kernel_type='primal', dim=30, lamb=1, gamma=1, T=10):\n",
    "        '''\n",
    "        Init func\n",
    "        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf'\n",
    "        :param dim: dimension after transfer\n",
    "        :param lamb: lambda value in equation\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        :param T: iteration number\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.dim = dim\n",
    "        self.lamb = lamb\n",
    "        self.gamma = gamma\n",
    "        self.T = T\n",
    "\n",
    "    def fit_predict(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Transform and Predict using 1NN as JDA paper did\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Ys: ns * 1, source label\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param Yt: nt * 1, target label\n",
    "        :return: acc, y_pred, list_acc\n",
    "        '''\n",
    "        list_acc = []\n",
    "        X = np.hstack((Xs.T, Xt.T))\n",
    "        #X /= np.linalg.norm(X, axis=0)\n",
    "        X = np.true_divide(X,np.linalg.norm(X, axis=0))\n",
    "        m, n = X.shape\n",
    "        ns, nt = len(Xs), len(Xt)\n",
    "        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))\n",
    "        C = len(np.unique(Ys))\n",
    "        H = np.eye(n) - 1 / n * np.ones((n, n))\n",
    "\n",
    "        M = 0\n",
    "        Y_tar_pseudo = None\n",
    "        for t in range(self.T):\n",
    "            N = 0\n",
    "            M0 = e * e.T * C\n",
    "            if Y_tar_pseudo is not None and len(Y_tar_pseudo) == nt:\n",
    "                for c in range(1, C + 1):\n",
    "                    e = np.zeros((n, 1))\n",
    "                    tt = Ys == c\n",
    "                    e[np.where(tt == True)] = 1 / len(Ys[np.where(Ys == c)])\n",
    "                    yy = Y_tar_pseudo == c\n",
    "                    ind = np.where(yy == True)\n",
    "                    inds = [item + ns for item in ind]\n",
    "                    e[tuple(inds)] = -1 / len(Y_tar_pseudo[np.where(Y_tar_pseudo == c)])\n",
    "                    e[np.isinf(e)] = 0\n",
    "                    N = N + np.dot(e, e.T)\n",
    "            M = M0 + N\n",
    "            M = M / np.linalg.norm(M, 'fro')\n",
    "            K = kernel(self.kernel_type, X, None, gamma=self.gamma)\n",
    "            n_eye = m if self.kernel_type == 'primal' else n\n",
    "            a, b = np.linalg.multi_dot([K, M, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])\n",
    "            w, V = scipy.linalg.eig(a, b)\n",
    "            ind = np.argsort(w)\n",
    "            A = V[:, ind[:self.dim]]\n",
    "            Z = np.dot(A.T, K)\n",
    "            Z /= np.linalg.norm(Z, axis=0)\n",
    "            Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T\n",
    "\n",
    "            clf = KNeighborsClassifier(n_neighbors=1)\n",
    "            clf.fit(Xs_new, Ys.ravel())\n",
    "            Y_tar_pseudo = clf.predict(Xt_new)\n",
    "            acc = sklearn.metrics.accuracy_score(Yt, Y_tar_pseudo)\n",
    "            list_acc.append(acc)\n",
    "            print('JDA iteration [{}/{}]: Acc: {:.4f}'.format(t + 1, self.T, acc))\n",
    "        return acc, Y_tar_pseudo, list_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDA iteration [1/10]: Acc: 0.8089\n",
      "JDA iteration [2/10]: Acc: 0.8217\n",
      "JDA iteration [3/10]: Acc: 0.8153\n",
      "JDA iteration [4/10]: Acc: 0.8153\n",
      "JDA iteration [5/10]: Acc: 0.8089\n",
      "JDA iteration [6/10]: Acc: 0.8153\n",
      "JDA iteration [7/10]: Acc: 0.8089\n",
      "JDA iteration [8/10]: Acc: 0.8153\n",
      "JDA iteration [9/10]: Acc: 0.8089\n",
      "JDA iteration [10/10]: Acc: 0.8153\n",
      "Classification accuracy on webcam_SURF_L10.mat v.s. dslr_SURF_L10.mat = 0.8152866242038217\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    domains = ['caltech_SURF_L10.mat', 'amazon_SURF_L10.mat', 'webcam_SURF_L10.mat', 'dslr_SURF_L10.mat']\n",
    "    for i in [2]:\n",
    "        for j in [3]:\n",
    "            if i != j:\n",
    "                src, tar = 'data\\\\' + domains[i], 'data\\\\' + domains[j]\n",
    "                src_domain, tar_domain = scipy.io.loadmat(src), scipy.io.loadmat(tar)\n",
    "                Xs, Ys, Xt, Yt = src_domain['fts'], src_domain['labels'], tar_domain['fts'], tar_domain['labels']\n",
    "                jda = JDA(kernel_type='primal', dim=30, lamb=1, gamma=1)\n",
    "                acc, ypre, list_acc = jda.fit_predict(Xs, Ys, Xt, Yt)\n",
    "                print(\"Classification accuracy on\" ,domains[i], \"v.s.\", domains[j], \"=\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
