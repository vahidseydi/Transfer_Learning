{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geodesic Flow Kernel (GFK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GFK Method Steps:\n",
    "    \n",
    "1) Determining the optimal dimensions for common domain subspace;\n",
    "2) Create geodesic curve;\n",
    "3) Calculate the geodesic flow kernel;\n",
    "4) Use the kernel to build the classifier with labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "Gong B, Shi Y, Sha F, et al. Geodesic flow kernel for unsupervised domain adaptation[C]//2012 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2012: 2066-2073."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import bob.learn\n",
    "import bob.learn.linear\n",
    "import bob.math\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFK:\n",
    "    def __init__(self, dim=20):\n",
    "        '''\n",
    "        Init func\n",
    "        :param dim: dimension after GFK\n",
    "        '''\n",
    "        self.dim = dim\n",
    "        self.eps = 1e-20\n",
    "\n",
    "    def fit(self, Xs, Xt, norm_inputs=None):\n",
    "        '''\n",
    "        Obtain the kernel G\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param norm_inputs: normalize the inputs or not\n",
    "        :return: GFK kernel G\n",
    "        '''\n",
    "        if norm_inputs:\n",
    "            source, mu_source, std_source = self.znorm(Xs)\n",
    "            target, mu_target, std_target = self.znorm(Xt)\n",
    "        else:\n",
    "            mu_source = np.zeros(shape=(Xs.shape[1]))\n",
    "            std_source = np.ones(shape=(Xs.shape[1]))\n",
    "            mu_target = np.zeros(shape=(Xt.shape[1]))\n",
    "            std_target = np.ones(shape=(Xt.shape[1]))\n",
    "            source = Xs\n",
    "            target = Xt\n",
    "\n",
    "        Ps = self.train_pca(source, mu_source, std_source, 0.99)\n",
    "        Pt = self.train_pca(target, mu_target, std_target, 0.99)\n",
    "        Ps = np.hstack((Ps.weights, scipy.linalg.null_space(Ps.weights.T)))\n",
    "        Pt = Pt.weights[:, :self.dim]\n",
    "        N = Ps.shape[1]\n",
    "        dim = Pt.shape[1]\n",
    "\n",
    "        # Principal angles between subspaces\n",
    "        QPt = np.dot(Ps.T, Pt)\n",
    "\n",
    "        # [V1,V2,V,Gam,Sig] = gsvd(QPt(1:dim,:), QPt(dim+1:end,:));\n",
    "        A = QPt[0:dim, :].copy()\n",
    "        B = QPt[dim:, :].copy()\n",
    "\n",
    "        # Equation (2)\n",
    "        [V1, V2, V, Gam, Sig] = bob.math.gsvd(A, B)\n",
    "        V2 = -V2\n",
    "\n",
    "        # Some sanity checks with the GSVD\n",
    "        I = np.eye(V1.shape[1])\n",
    "        I_check = np.dot(Gam.T, Gam) + np.dot(Sig.T, Sig)\n",
    "        assert np.sum(abs(I - I_check)) < 1e-10\n",
    "\n",
    "        theta = np.arccos(np.diagonal(Gam))\n",
    "\n",
    "        # Equation (6)\n",
    "        B1 = np.diag(0.5 * (1 + (np.sin(2 * theta) / (2. * np.maximum\n",
    "        (theta, 1e-20)))))\n",
    "        B2 = np.diag(0.5 * ((np.cos(2 * theta) - 1) / (2 * np.maximum(\n",
    "            theta, self.eps))))\n",
    "        B3 = B2\n",
    "        B4 = np.diag(0.5 * (1 - (np.sin(2 * theta) / (2. * np.maximum\n",
    "        (theta, self.eps)))))\n",
    "\n",
    "        # Equation (9) of the suplementary matetial\n",
    "        delta1_1 = np.hstack((V1, np.zeros(shape=(dim, N - dim))))\n",
    "        delta1_2 = np.hstack((np.zeros(shape=(N - dim, dim)), V2))\n",
    "        delta1 = np.vstack((delta1_1, delta1_2))\n",
    "\n",
    "        delta2_1 = np.hstack((B1, B2, np.zeros(shape=(dim, N - 2 * dim))))\n",
    "        delta2_2 = np.hstack((B3, B4, np.zeros(shape=(dim, N - 2 * dim))))\n",
    "        delta2_3 = np.zeros(shape=(N - 2 * dim, N))\n",
    "        delta2 = np.vstack((delta2_1, delta2_2, delta2_3))\n",
    "\n",
    "        delta3_1 = np.hstack((V1, np.zeros(shape=(dim, N - dim))))\n",
    "        delta3_2 = np.hstack((np.zeros(shape=(N - dim, dim)), V2))\n",
    "        delta3 = np.vstack((delta3_1, delta3_2)).T\n",
    "\n",
    "        delta = np.dot(np.dot(delta1, delta2), delta3)\n",
    "        G = np.dot(np.dot(Ps, delta), Ps.T)\n",
    "        sqG = scipy.real(scipy.linalg.fractional_matrix_power(G, 0.5))\n",
    "        Xs_new, Xt_new = np.dot(sqG, Xs.T).T, np.dot(sqG, Xt.T).T\n",
    "        return G, Xs_new, Xt_new\n",
    "\n",
    "    def fit_predict(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Fit and use 1NN to classify\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Ys: ns * 1, source label\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param Yt: nt * 1, target label\n",
    "        :return: Accuracy, predicted labels of target domain, and G\n",
    "        '''\n",
    "        G, Xs_new, Xt_new = self.fit(Xs, Xt)\n",
    "        clf = KNeighborsClassifier(n_neighbors=1)\n",
    "        clf.fit(Xs_new, Ys.ravel())\n",
    "        y_pred = clf.predict(Xt_new)\n",
    "        acc = np.mean(y_pred == Yt.ravel())\n",
    "        return acc, y_pred, G\n",
    "\n",
    "    def principal_angles(self, Ps, Pt):\n",
    "        \"\"\"\n",
    "        Compute the principal angles between source (:math:`P_s`) and target (:math:`P_t`) subspaces in a Grassman which is defined as the following:\n",
    "        :math:`d^{2}(P_s, P_t) = \\sum_{i}( \\theta_i^{2} )`,\n",
    "        \"\"\"\n",
    "        # S = cos(theta_1, theta_2, ..., theta_n)\n",
    "        _, S, _ = np.linalg.svd(np.dot(Ps.T, Pt))\n",
    "        thetas_squared = np.arccos(S) ** 2\n",
    "\n",
    "        return np.sum(thetas_squared)\n",
    "\n",
    "    def train_pca(self, data, mu_data, std_data, subspace_dim):\n",
    "        '''\n",
    "        Modified PCA function, different from the one in sklearn\n",
    "        :param data: data matrix\n",
    "        :param mu_data: mu\n",
    "        :param std_data: std\n",
    "        :param subspace_dim: dim\n",
    "        :return: a wrapped machine object\n",
    "        '''\n",
    "        t = bob.learn.linear.PCATrainer()\n",
    "        machine, variances = t.train(data)\n",
    "\n",
    "        # For re-shaping, we need to copy...\n",
    "        variances = variances.copy()\n",
    "\n",
    "        # compute variance percentage, if desired\n",
    "        if isinstance(subspace_dim, float):\n",
    "            cummulated = np.cumsum(variances) / np.sum(variances)\n",
    "            for index in range(len(cummulated)):\n",
    "                if cummulated[index] > subspace_dim:\n",
    "                    subspace_dim = index\n",
    "                    break\n",
    "            subspace_dim = index\n",
    "        machine.resize(machine.shape[0], subspace_dim)\n",
    "        machine.input_subtract = mu_data\n",
    "        machine.input_divide = std_data\n",
    "\n",
    "        return machine\n",
    "\n",
    "    def znorm(self, data):\n",
    "        \"\"\"\n",
    "        Z-Normaliza\n",
    "        \"\"\"\n",
    "        mu = np.average(data, axis=0)\n",
    "        std = np.std(data, axis=0)\n",
    "        data = (data - mu) / std\n",
    "        return data, mu, std\n",
    "\n",
    "    def subspace_disagreement_measure(self, Ps, Pt, Pst):\n",
    "        \"\"\"\n",
    "        Get the best value for the number of subspaces\n",
    "        For more details, read section 3.4 of the paper.\n",
    "        **Parameters**\n",
    "          Ps: Source subspace\n",
    "          Pt: Target subspace\n",
    "          Pst: Source + Target subspace\n",
    "        \"\"\"\n",
    "\n",
    "        def compute_angles(A, B):\n",
    "            _, S, _ = np.linalg.svd(np.dot(A.T, B))\n",
    "            S[np.where(np.isclose(S, 1, atol=self.eps) == True)[0]] = 1\n",
    "            return np.arccos(S)\n",
    "\n",
    "        max_d = min(Ps.shape[1], Pt.shape[1], Pst.shape[1])\n",
    "        alpha_d = compute_angles(Ps, Pst)\n",
    "        beta_d = compute_angles(Pt, Pst)\n",
    "        d = 0.5 * (np.sin(alpha_d) + np.sin(beta_d))\n",
    "        return np.argmax(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    domains = ['caltech_SURF_L10.mat', 'amazon_SURF_L10.mat', 'webcam_SURF_L10.mat', 'dslr_SURF_L10.mat']\n",
    "    for i in [2]:\n",
    "        for j in [3]:\n",
    "            if i != j:\n",
    "                src, tar = 'data\\\\' + domains[i], 'data\\\\' + domains[j]\n",
    "                src_domain, tar_domain = scipy.io.loadmat(src), scipy.io.loadmat(tar)\n",
    "                Xs, Ys, Xt, Yt = src_domain['feas'], src_domain['label'], tar_domain['feas'], tar_domain['label']\n",
    "                gfk = GFK(dim=20)\n",
    "                acc, ypred, G = gfk.fit_predict(Xs, Ys, Xt, Yt)\n",
    "                print(\"Classification accuracy on\" ,domains[i], \"v.s.\", domains[j], \"=\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
